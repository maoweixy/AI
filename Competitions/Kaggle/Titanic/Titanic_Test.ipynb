{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:40.899892Z",
     "start_time": "2020-02-26T08:58:40.879334Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:30.664009Z",
     "iopub.status.busy": "2020-03-01T09:06:30.661200Z",
     "iopub.status.idle": "2020-03-01T09:06:30.818567Z",
     "shell.execute_reply": "2020-03-01T09:06:30.814093Z",
     "shell.execute_reply.started": "2020-03-01T09:06:30.663739Z"
    }
   },
   "outputs": [],
   "source": [
    "# package imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA（Exploratory Data Analysis）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:40.967537Z",
     "start_time": "2020-02-26T08:58:40.903693Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:30.822745Z",
     "iopub.status.busy": "2020-03-01T09:06:30.822451Z",
     "iopub.status.idle": "2020-03-01T09:06:31.051511Z",
     "shell.execute_reply": "2020-03-01T09:06:31.048583Z",
     "shell.execute_reply.started": "2020-03-01T09:06:30.822702Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('train.csv')\n",
    "titanic.drop(columns = ['PassengerId','Name','Ticket'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:40.992927Z",
     "start_time": "2020-02-26T08:58:40.972712Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.057517Z",
     "iopub.status.busy": "2020-03-01T09:06:31.057048Z",
     "iopub.status.idle": "2020-03-01T09:06:31.191909Z",
     "shell.execute_reply": "2020-03-01T09:06:31.189839Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.057311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Cabin     204 non-null    object \n",
      " 8   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.shape\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.035649Z",
     "start_time": "2020-02-26T08:58:40.999678Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.195863Z",
     "iopub.status.busy": "2020-03-01T09:06:31.194733Z",
     "iopub.status.idle": "2020-03-01T09:06:31.306892Z",
     "shell.execute_reply": "2020-03-01T09:06:31.305859Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.195315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pclass'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Sex'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Embarked'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = ['Age', 'SibSp','Parch','Fare', 'Cabin']\n",
    "cate_features = ['Pclass', 'Sex','Embarked']\n",
    "\n",
    "for feature in cate_features:\n",
    "    feature\n",
    "    titanic[feature].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.055694Z",
     "start_time": "2020-02-26T08:58:41.041346Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.313251Z",
     "iopub.status.busy": "2020-03-01T09:06:31.312619Z",
     "iopub.status.idle": "2020-03-01T09:06:31.348381Z",
     "shell.execute_reply": "2020-03-01T09:06:31.346183Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.313007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass     -0.338481\n",
       "Age        -0.077221\n",
       "SibSp      -0.035322\n",
       "Parch       0.081629\n",
       "Fare        0.257307\n",
       "Survived    1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = titanic.corr()\n",
    "corr_matrix['Survived'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去掉缺失值过多的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.350916Z",
     "iopub.status.busy": "2020-03-01T09:06:31.350624Z",
     "iopub.status.idle": "2020-03-01T09:06:31.364520Z",
     "shell.execute_reply": "2020-03-01T09:06:31.360730Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.350872Z"
    }
   },
   "outputs": [],
   "source": [
    "# titanic.drop(columns='Cabin', inplace=True)\n",
    "# titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用模型填补缺失值（Age）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.367292Z",
     "iopub.status.busy": "2020-03-01T09:06:31.366794Z",
     "iopub.status.idle": "2020-03-01T09:06:31.391691Z",
     "shell.execute_reply": "2020-03-01T09:06:31.388749Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.367210Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def set_missing_ages(df):\n",
    "\n",
    "    # 把已有的数值型特征取出来丢进Random Forest Regressor中\n",
    "    age_df = df[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "\n",
    "    # 乘客分成已知年龄和未知年龄两部分\n",
    "    known_age = age_df[age_df['Age'].notna()]\n",
    "    unknown_age = age_df[age_df['Age'].isna()]\n",
    "\n",
    "    # y即目标年龄\n",
    "    y = known_age.iloc[:, 0]\n",
    "\n",
    "    # X即特征属性值\n",
    "    X = known_age.iloc[:, 1:]\n",
    "\n",
    "    # fit到RandomForestRegressor之中\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(X, y)\n",
    "\n",
    "    # 用得到的模型进行未知年龄结果预测\n",
    "    predictedAges = rfr.predict(unknown_age.iloc[:, 1:])\n",
    "#     print predictedAges\n",
    "    # 用得到的预测结果填补原缺失数据\n",
    "    df.loc[df['Age'].isna(), 'Age' ] = predictedAges \n",
    "\n",
    "    return df, rfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age<10 =is_cild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.395270Z",
     "iopub.status.busy": "2020-03-01T09:06:31.394578Z",
     "iopub.status.idle": "2020-03-01T09:06:31.405028Z",
     "shell.execute_reply": "2020-03-01T09:06:31.403432Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.395172Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_child_type(df):\n",
    "    df['is_child'] = 0\n",
    "    df.loc[df['is_child']<11, 'is_child'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用有无缺失值去重新定义（Cabin）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.409999Z",
     "iopub.status.busy": "2020-03-01T09:06:31.409107Z",
     "iopub.status.idle": "2020-03-01T09:06:31.421361Z",
     "shell.execute_reply": "2020-03-01T09:06:31.419939Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.409539Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_Cabin_type(df):\n",
    "    df.loc[df['Cabin'].notna(), 'Cabin'] = 1\n",
    "    df.loc[df['Cabin'].isna(), 'Cabin'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理numeric、categorical数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.116782Z",
     "start_time": "2020-02-26T08:58:41.101796Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.424845Z",
     "iopub.status.busy": "2020-03-01T09:06:31.424394Z",
     "iopub.status.idle": "2020-03-01T09:06:31.460921Z",
     "shell.execute_reply": "2020-03-01T09:06:31.459587Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.424761Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "num_pipeline = make_pipeline(\n",
    "    FunctionTransformer(set_child_type),\n",
    "    FunctionTransformer(set_Cabin_type),\n",
    "    SimpleImputer(strategy=\"median\"), #缺失值用中位数代替\n",
    "    StandardScaler()#标准化\n",
    ")\n",
    "cate_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='unknown'), #离散型数据用unknown补全\n",
    "    OneHotEncoder(sparse=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.136478Z",
     "start_time": "2020-02-26T08:58:41.121883Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.463934Z",
     "iopub.status.busy": "2020-03-01T09:06:31.463112Z",
     "iopub.status.idle": "2020-03-01T09:06:31.536595Z",
     "shell.execute_reply": "2020-03-01T09:06:31.521683Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.463832Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "data_pipeline = make_column_transformer(\n",
    "    (num_pipeline, num_features),\n",
    "    (cate_pipeline, cate_features),\n",
    "    remainder='passthrough'\n",
    "    )\n",
    "# train_prepared = full_pipeline.fit_transform()\n",
    "# type(train_prepared)\n",
    "# train_prepared.shape\n",
    "\n",
    "# train_prepared = pd.DataFrame(train_prepared, columns=X_train.columns)\n",
    "# train_prepared.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择。比如：查看特征工程后的相关系数。待定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.145870Z",
     "start_time": "2020-02-26T08:58:41.140034Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.543717Z",
     "iopub.status.busy": "2020-03-01T09:06:31.543226Z",
     "iopub.status.idle": "2020-03-01T09:06:31.551485Z",
     "shell.execute_reply": "2020-03-01T09:06:31.550254Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.543632Z"
    }
   },
   "outputs": [],
   "source": [
    "# corr_matrix = titanic.corr()\n",
    "# corr_matrix['Survived'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.166564Z",
     "start_time": "2020-02-26T08:58:41.148687Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.554431Z",
     "iopub.status.busy": "2020-03-01T09:06:31.553903Z",
     "iopub.status.idle": "2020-03-01T09:06:31.645361Z",
     "shell.execute_reply": "2020-03-01T09:06:31.642913Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.554369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_titanic = titanic.drop('Survived', axis = 1)\n",
    "label = titanic['Survived']\n",
    "\n",
    "\n",
    "# 将数据集按照`3:7`的比例，切分为训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_titanic, label, test_size = 0.3, random_state = 42)\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:31.663215Z",
     "iopub.status.busy": "2020-03-01T09:06:31.662629Z",
     "iopub.status.idle": "2020-03-01T09:06:32.671442Z",
     "shell.execute_reply": "2020-03-01T09:06:32.670034Z",
     "shell.execute_reply.started": "2020-03-01T09:06:31.663114Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maowei/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/Users/maowei/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# 用模型填补Age缺失值（思考怎么加入Pipline）\n",
    "X_train, rfr = set_missing_ages(X_train)\n",
    "tmp_df = X_test[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "null_age = tmp_df[X_test['Age'].isna()]\n",
    "X = null_age.iloc[:, 1:]\n",
    "predictedAges = rfr.predict(X)\n",
    "X_test.loc[X_test['Age'].isna(), 'Age'] = predictedAges\n",
    "\n",
    "#加入pipeline出错，先手动处理\n",
    "# X_train = set_child_type(X_train)\n",
    "# X_train = set_Cabin_type(X_train)\n",
    "\n",
    "# X_test = set_child_type(X_test)\n",
    "# X_test = set_Cabin_type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T08:56:28.320685Z",
     "iopub.status.busy": "2020-03-01T08:56:28.320215Z",
     "iopub.status.idle": "2020-03-01T08:56:28.398115Z",
     "shell.execute_reply": "2020-03-01T08:56:28.393048Z",
     "shell.execute_reply.started": "2020-03-01T08:56:28.320556Z"
    }
   },
   "source": [
    "# tem = data_pipeline.fit_transform(X_train)\n",
    "tem = num_pipeline.fit_transform(X_train[num_features])\n",
    "type(tem)\n",
    "tem.shape\n",
    "tem[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合pipeline（模型+数据处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:41.181816Z",
     "start_time": "2020-02-26T08:58:41.173441Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:32.674177Z",
     "iopub.status.busy": "2020-03-01T09:06:32.673293Z",
     "iopub.status.idle": "2020-03-01T09:06:32.681818Z",
     "shell.execute_reply": "2020-03-01T09:06:32.680095Z",
     "shell.execute_reply.started": "2020-03-01T09:06:32.673839Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_pipeline(model):\n",
    "    return make_pipeline(data_pipeline, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:32.686742Z",
     "iopub.status.busy": "2020-03-01T09:06:32.686245Z",
     "iopub.status.idle": "2020-03-01T09:06:32.726137Z",
     "shell.execute_reply": "2020-03-01T09:06:32.707077Z",
     "shell.execute_reply.started": "2020-03-01T09:06:32.686653Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:32.759838Z",
     "iopub.status.busy": "2020-03-01T09:06:32.739579Z",
     "iopub.status.idle": "2020-03-01T09:06:32.784087Z",
     "shell.execute_reply": "2020-03-01T09:06:32.778293Z",
     "shell.execute_reply.started": "2020-03-01T09:06:32.759726Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:43.246542Z",
     "start_time": "2020-02-26T08:58:41.200272Z"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-03-01T08:58:54.610580Z",
     "iopub.status.busy": "2020-03-01T08:58:54.610146Z",
     "iopub.status.idle": "2020-03-01T08:58:55.117873Z",
     "shell.execute_reply": "2020-03-01T08:58:55.116747Z",
     "shell.execute_reply.started": "2020-03-01T08:58:54.610392Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('pipeline-1',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('functiontransformer-1',\n",
       "                                                     FunctionTransformer(accept_sparse=False,\n",
       "                                                                         check_inverse=True,\n",
       "                                                                         func=<function set_child_type at 0x1a1c79add0>,\n",
       "                                                                         inv_kw_args=None,\n",
       "                                                                         inverse_func=None,\n",
       "                                                                         kw_args=None,\n",
       "                                                                         validate=False)),\n",
       "                                                    (...\n",
       "                                   ('pipeline-2',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(add_indicator=False,\n",
       "                                                                   copy=True,\n",
       "                                                                   fill_value='unknown',\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='constant',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('onehotencoder',\n",
       "                                                     OneHotEncoder(categories='auto',\n",
       "                                                                   drop=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='error',\n",
       "                                                                   sparse=False))],\n",
       "                                             verbose=False),\n",
       "                                    ['Pclass', 'Sex', 'Embarked'])],\n",
       "                     verbose=False)),\n",
       "  ('stackingclassifier',\n",
       "   StackingClassifier(cv=None,\n",
       "                      estimators=[('mlp_clf',\n",
       "                                   MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                                 batch_size='auto', beta_1=0.9,\n",
       "                                                 beta_2=0.999,\n",
       "                                                 early_stopping=False,\n",
       "                                                 epsilon=1e-08,\n",
       "                                                 hidden_layer_sizes=(100,),\n",
       "                                                 learning_rate='constant',\n",
       "                                                 learning_rate_init=0.001,\n",
       "                                                 max_fun=15000, max_iter=200,\n",
       "                                                 momentum=0.9, n_iter_no_change=10,\n",
       "                                                 nesterovs_momentum=True,\n",
       "                                                 power_t=0.5, random...\n",
       "                                                             criterion='gini',\n",
       "                                                             max_depth=None,\n",
       "                                                             max_features='auto',\n",
       "                                                             max_leaf_nodes=None,\n",
       "                                                             max_samples=None,\n",
       "                                                             min_impurity_decrease=0.0,\n",
       "                                                             min_impurity_split=None,\n",
       "                                                             min_samples_leaf=1,\n",
       "                                                             min_samples_split=2,\n",
       "                                                             min_weight_fraction_leaf=0.0,\n",
       "                                                             n_estimators=100,\n",
       "                                                             n_jobs=None,\n",
       "                                                             oob_score=False,\n",
       "                                                             random_state=None,\n",
       "                                                             verbose=0,\n",
       "                                                             warm_start=False),\n",
       "                      n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                      verbose=0))],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('pipeline-1',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('functiontransformer-1',\n",
       "                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                       check_inverse=True,\n",
       "                                                                       func=<function set_child_type at 0x1a1c79add0>,\n",
       "                                                                       inv_kw_args=None,\n",
       "                                                                       inverse_func=None,\n",
       "                                                                       kw_args=None,\n",
       "                                                                       validate=False)),\n",
       "                                                  (...\n",
       "                                 ('pipeline-2',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                 copy=True,\n",
       "                                                                 fill_value='unknown',\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='constant',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('onehotencoder',\n",
       "                                                   OneHotEncoder(categories='auto',\n",
       "                                                                 drop=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='error',\n",
       "                                                                 sparse=False))],\n",
       "                                           verbose=False),\n",
       "                                  ['Pclass', 'Sex', 'Embarked'])],\n",
       "                   verbose=False),\n",
       " 'stackingclassifier': StackingClassifier(cv=None,\n",
       "                    estimators=[('mlp_clf',\n",
       "                                 MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                               batch_size='auto', beta_1=0.9,\n",
       "                                               beta_2=0.999,\n",
       "                                               early_stopping=False,\n",
       "                                               epsilon=1e-08,\n",
       "                                               hidden_layer_sizes=(100,),\n",
       "                                               learning_rate='constant',\n",
       "                                               learning_rate_init=0.001,\n",
       "                                               max_fun=15000, max_iter=200,\n",
       "                                               momentum=0.9, n_iter_no_change=10,\n",
       "                                               nesterovs_momentum=True,\n",
       "                                               power_t=0.5, random...\n",
       "                                                           criterion='gini',\n",
       "                                                           max_depth=None,\n",
       "                                                           max_features='auto',\n",
       "                                                           max_leaf_nodes=None,\n",
       "                                                           max_samples=None,\n",
       "                                                           min_impurity_decrease=0.0,\n",
       "                                                           min_impurity_split=None,\n",
       "                                                           min_samples_leaf=1,\n",
       "                                                           min_samples_split=2,\n",
       "                                                           min_weight_fraction_leaf=0.0,\n",
       "                                                           n_estimators=100,\n",
       "                                                           n_jobs=None,\n",
       "                                                           oob_score=False,\n",
       "                                                           random_state=None,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                    n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                    verbose=0),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'passthrough',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('pipeline-1',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('functiontransformer-1',\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                        func=<function set_child_type at 0x1a1c79add0>,\n",
       "                                        inv_kw_args=None, inverse_func=None,\n",
       "                                        kw_args=None, validate=False)),\n",
       "                   ('functiontransformer-2',\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                        func=<function set_Cabin_type at 0x1a1c76de60>,\n",
       "                                        inv_kw_args=None, inverse_func=None,\n",
       "                                        kw_args=None, validate=False)),\n",
       "                   ('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                  missing_values=nan, strategy='median',\n",
       "                                  verbose=0)),\n",
       "                   ('standardscaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "            verbose=False),\n",
       "   ['Age', 'SibSp', 'Parch', 'Fare', 'Cabin']),\n",
       "  ('pipeline-2',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(add_indicator=False, copy=True,\n",
       "                                  fill_value='unknown', missing_values=nan,\n",
       "                                  strategy='constant', verbose=0)),\n",
       "                   ('onehotencoder',\n",
       "                    OneHotEncoder(categories='auto', drop=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='error', sparse=False))],\n",
       "            verbose=False),\n",
       "   ['Pclass', 'Sex', 'Embarked'])],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__pipeline-1': Pipeline(memory=None,\n",
       "          steps=[('functiontransformer-1',\n",
       "                  FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                      func=<function set_child_type at 0x1a1c79add0>,\n",
       "                                      inv_kw_args=None, inverse_func=None,\n",
       "                                      kw_args=None, validate=False)),\n",
       "                 ('functiontransformer-2',\n",
       "                  FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                      func=<function set_Cabin_type at 0x1a1c76de60>,\n",
       "                                      inv_kw_args=None, inverse_func=None,\n",
       "                                      kw_args=None, validate=False)),\n",
       "                 ('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                                missing_values=nan, strategy='median',\n",
       "                                verbose=0)),\n",
       "                 ('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-2': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(add_indicator=False, copy=True,\n",
       "                                fill_value='unknown', missing_values=nan,\n",
       "                                strategy='constant', verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categories='auto', drop=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='error', sparse=False))],\n",
       "          verbose=False),\n",
       " 'columntransformer__pipeline-1__memory': None,\n",
       " 'columntransformer__pipeline-1__steps': [('functiontransformer-1',\n",
       "   FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function set_child_type at 0x1a1c79add0>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       validate=False)),\n",
       "  ('functiontransformer-2',\n",
       "   FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function set_Cabin_type at 0x1a1c76de60>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       validate=False)),\n",
       "  ('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                 missing_values=nan, strategy='median', verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'columntransformer__pipeline-1__verbose': False,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function set_child_type at 0x1a1c79add0>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     validate=False),\n",
       " 'columntransformer__pipeline-1__functiontransformer-2': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function set_Cabin_type at 0x1a1c76de60>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     validate=False),\n",
       " 'columntransformer__pipeline-1__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "               missing_values=nan, strategy='median', verbose=0),\n",
       " 'columntransformer__pipeline-1__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__accept_sparse': False,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__check_inverse': True,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__func': <function __main__.set_child_type(df)>,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__inv_kw_args': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__inverse_func': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__kw_args': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-1__validate': False,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__accept_sparse': False,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__check_inverse': True,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__func': <function __main__.set_Cabin_type(df)>,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__inv_kw_args': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__inverse_func': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__kw_args': None,\n",
       " 'columntransformer__pipeline-1__functiontransformer-2__validate': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-1__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-1__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-1__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-1__simpleimputer__strategy': 'median',\n",
       " 'columntransformer__pipeline-1__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-1__standardscaler__copy': True,\n",
       " 'columntransformer__pipeline-1__standardscaler__with_mean': True,\n",
       " 'columntransformer__pipeline-1__standardscaler__with_std': True,\n",
       " 'columntransformer__pipeline-2__memory': None,\n",
       " 'columntransformer__pipeline-2__steps': [('simpleimputer',\n",
       "   SimpleImputer(add_indicator=False, copy=True, fill_value='unknown',\n",
       "                 missing_values=nan, strategy='constant', verbose=0)),\n",
       "  ('onehotencoder',\n",
       "   OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "                 handle_unknown='error', sparse=False))],\n",
       " 'columntransformer__pipeline-2__verbose': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value='unknown',\n",
       "               missing_values=nan, strategy='constant', verbose=0),\n",
       " 'columntransformer__pipeline-2__onehotencoder': OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "               handle_unknown='error', sparse=False),\n",
       " 'columntransformer__pipeline-2__simpleimputer__add_indicator': False,\n",
       " 'columntransformer__pipeline-2__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-2__simpleimputer__fill_value': 'unknown',\n",
       " 'columntransformer__pipeline-2__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-2__simpleimputer__strategy': 'constant',\n",
       " 'columntransformer__pipeline-2__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-2__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__pipeline-2__onehotencoder__drop': None,\n",
       " 'columntransformer__pipeline-2__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__pipeline-2__onehotencoder__handle_unknown': 'error',\n",
       " 'columntransformer__pipeline-2__onehotencoder__sparse': False,\n",
       " 'stackingclassifier__cv': None,\n",
       " 'stackingclassifier__estimators': [('mlp_clf',\n",
       "   MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                 beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "                 hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                 learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "                 momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "                 power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "                 tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "                 warm_start=False)),\n",
       "  ('ab_clf',\n",
       "   AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                      n_estimators=50, random_state=None)),\n",
       "  ('log_clf',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False)),\n",
       "  ('svm_clf',\n",
       "   SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "       decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "       max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "       verbose=False)),\n",
       "  ('rf_clf',\n",
       "   RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                          criterion='gini', max_depth=None, max_features='auto',\n",
       "                          max_leaf_nodes=None, max_samples=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_jobs=None, oob_score=False, random_state=None,\n",
       "                          verbose=0, warm_start=False)),\n",
       "  ('gbdt_clf',\n",
       "   GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                              max_features=None, max_leaf_nodes=None,\n",
       "                              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                              min_samples_leaf=1, min_samples_split=2,\n",
       "                              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                              n_iter_no_change=None, presort='deprecated',\n",
       "                              random_state=None, subsample=1.0, tol=0.0001,\n",
       "                              validation_fraction=0.1, verbose=0,\n",
       "                              warm_start=False))],\n",
       " 'stackingclassifier__final_estimator__bootstrap': True,\n",
       " 'stackingclassifier__final_estimator__ccp_alpha': 0.0,\n",
       " 'stackingclassifier__final_estimator__class_weight': None,\n",
       " 'stackingclassifier__final_estimator__criterion': 'gini',\n",
       " 'stackingclassifier__final_estimator__max_depth': None,\n",
       " 'stackingclassifier__final_estimator__max_features': 'auto',\n",
       " 'stackingclassifier__final_estimator__max_leaf_nodes': None,\n",
       " 'stackingclassifier__final_estimator__max_samples': None,\n",
       " 'stackingclassifier__final_estimator__min_impurity_decrease': 0.0,\n",
       " 'stackingclassifier__final_estimator__min_impurity_split': None,\n",
       " 'stackingclassifier__final_estimator__min_samples_leaf': 1,\n",
       " 'stackingclassifier__final_estimator__min_samples_split': 2,\n",
       " 'stackingclassifier__final_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'stackingclassifier__final_estimator__n_estimators': 100,\n",
       " 'stackingclassifier__final_estimator__n_jobs': None,\n",
       " 'stackingclassifier__final_estimator__oob_score': False,\n",
       " 'stackingclassifier__final_estimator__random_state': None,\n",
       " 'stackingclassifier__final_estimator__verbose': 0,\n",
       " 'stackingclassifier__final_estimator__warm_start': False,\n",
       " 'stackingclassifier__final_estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'stackingclassifier__n_jobs': None,\n",
       " 'stackingclassifier__passthrough': False,\n",
       " 'stackingclassifier__stack_method': 'auto',\n",
       " 'stackingclassifier__verbose': 0,\n",
       " 'stackingclassifier__mlp_clf': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "               power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "               warm_start=False),\n",
       " 'stackingclassifier__ab_clf': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                    n_estimators=50, random_state=None),\n",
       " 'stackingclassifier__log_clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'stackingclassifier__svm_clf': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "     verbose=False),\n",
       " 'stackingclassifier__rf_clf': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'stackingclassifier__gbdt_clf': GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                            min_samples_leaf=1, min_samples_split=2,\n",
       "                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                            n_iter_no_change=None, presort='deprecated',\n",
       "                            random_state=None, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " 'stackingclassifier__mlp_clf__activation': 'relu',\n",
       " 'stackingclassifier__mlp_clf__alpha': 0.0001,\n",
       " 'stackingclassifier__mlp_clf__batch_size': 'auto',\n",
       " 'stackingclassifier__mlp_clf__beta_1': 0.9,\n",
       " 'stackingclassifier__mlp_clf__beta_2': 0.999,\n",
       " 'stackingclassifier__mlp_clf__early_stopping': False,\n",
       " 'stackingclassifier__mlp_clf__epsilon': 1e-08,\n",
       " 'stackingclassifier__mlp_clf__hidden_layer_sizes': (100,),\n",
       " 'stackingclassifier__mlp_clf__learning_rate': 'constant',\n",
       " 'stackingclassifier__mlp_clf__learning_rate_init': 0.001,\n",
       " 'stackingclassifier__mlp_clf__max_fun': 15000,\n",
       " 'stackingclassifier__mlp_clf__max_iter': 200,\n",
       " 'stackingclassifier__mlp_clf__momentum': 0.9,\n",
       " 'stackingclassifier__mlp_clf__n_iter_no_change': 10,\n",
       " 'stackingclassifier__mlp_clf__nesterovs_momentum': True,\n",
       " 'stackingclassifier__mlp_clf__power_t': 0.5,\n",
       " 'stackingclassifier__mlp_clf__random_state': None,\n",
       " 'stackingclassifier__mlp_clf__shuffle': True,\n",
       " 'stackingclassifier__mlp_clf__solver': 'adam',\n",
       " 'stackingclassifier__mlp_clf__tol': 0.0001,\n",
       " 'stackingclassifier__mlp_clf__validation_fraction': 0.1,\n",
       " 'stackingclassifier__mlp_clf__verbose': False,\n",
       " 'stackingclassifier__mlp_clf__warm_start': False,\n",
       " 'stackingclassifier__ab_clf__algorithm': 'SAMME.R',\n",
       " 'stackingclassifier__ab_clf__base_estimator': None,\n",
       " 'stackingclassifier__ab_clf__learning_rate': 1.0,\n",
       " 'stackingclassifier__ab_clf__n_estimators': 50,\n",
       " 'stackingclassifier__ab_clf__random_state': None,\n",
       " 'stackingclassifier__log_clf__C': 1.0,\n",
       " 'stackingclassifier__log_clf__class_weight': None,\n",
       " 'stackingclassifier__log_clf__dual': False,\n",
       " 'stackingclassifier__log_clf__fit_intercept': True,\n",
       " 'stackingclassifier__log_clf__intercept_scaling': 1,\n",
       " 'stackingclassifier__log_clf__l1_ratio': None,\n",
       " 'stackingclassifier__log_clf__max_iter': 100,\n",
       " 'stackingclassifier__log_clf__multi_class': 'auto',\n",
       " 'stackingclassifier__log_clf__n_jobs': None,\n",
       " 'stackingclassifier__log_clf__penalty': 'l2',\n",
       " 'stackingclassifier__log_clf__random_state': None,\n",
       " 'stackingclassifier__log_clf__solver': 'lbfgs',\n",
       " 'stackingclassifier__log_clf__tol': 0.0001,\n",
       " 'stackingclassifier__log_clf__verbose': 0,\n",
       " 'stackingclassifier__log_clf__warm_start': False,\n",
       " 'stackingclassifier__svm_clf__C': 1.0,\n",
       " 'stackingclassifier__svm_clf__break_ties': False,\n",
       " 'stackingclassifier__svm_clf__cache_size': 200,\n",
       " 'stackingclassifier__svm_clf__class_weight': None,\n",
       " 'stackingclassifier__svm_clf__coef0': 0.0,\n",
       " 'stackingclassifier__svm_clf__decision_function_shape': 'ovr',\n",
       " 'stackingclassifier__svm_clf__degree': 3,\n",
       " 'stackingclassifier__svm_clf__gamma': 'scale',\n",
       " 'stackingclassifier__svm_clf__kernel': 'rbf',\n",
       " 'stackingclassifier__svm_clf__max_iter': -1,\n",
       " 'stackingclassifier__svm_clf__probability': True,\n",
       " 'stackingclassifier__svm_clf__random_state': None,\n",
       " 'stackingclassifier__svm_clf__shrinking': True,\n",
       " 'stackingclassifier__svm_clf__tol': 0.001,\n",
       " 'stackingclassifier__svm_clf__verbose': False,\n",
       " 'stackingclassifier__rf_clf__bootstrap': True,\n",
       " 'stackingclassifier__rf_clf__ccp_alpha': 0.0,\n",
       " 'stackingclassifier__rf_clf__class_weight': None,\n",
       " 'stackingclassifier__rf_clf__criterion': 'gini',\n",
       " 'stackingclassifier__rf_clf__max_depth': None,\n",
       " 'stackingclassifier__rf_clf__max_features': 'auto',\n",
       " 'stackingclassifier__rf_clf__max_leaf_nodes': None,\n",
       " 'stackingclassifier__rf_clf__max_samples': None,\n",
       " 'stackingclassifier__rf_clf__min_impurity_decrease': 0.0,\n",
       " 'stackingclassifier__rf_clf__min_impurity_split': None,\n",
       " 'stackingclassifier__rf_clf__min_samples_leaf': 1,\n",
       " 'stackingclassifier__rf_clf__min_samples_split': 2,\n",
       " 'stackingclassifier__rf_clf__min_weight_fraction_leaf': 0.0,\n",
       " 'stackingclassifier__rf_clf__n_estimators': 100,\n",
       " 'stackingclassifier__rf_clf__n_jobs': None,\n",
       " 'stackingclassifier__rf_clf__oob_score': False,\n",
       " 'stackingclassifier__rf_clf__random_state': None,\n",
       " 'stackingclassifier__rf_clf__verbose': 0,\n",
       " 'stackingclassifier__rf_clf__warm_start': False,\n",
       " 'stackingclassifier__gbdt_clf__ccp_alpha': 0.0,\n",
       " 'stackingclassifier__gbdt_clf__criterion': 'friedman_mse',\n",
       " 'stackingclassifier__gbdt_clf__init': None,\n",
       " 'stackingclassifier__gbdt_clf__learning_rate': 0.1,\n",
       " 'stackingclassifier__gbdt_clf__loss': 'deviance',\n",
       " 'stackingclassifier__gbdt_clf__max_depth': 3,\n",
       " 'stackingclassifier__gbdt_clf__max_features': None,\n",
       " 'stackingclassifier__gbdt_clf__max_leaf_nodes': None,\n",
       " 'stackingclassifier__gbdt_clf__min_impurity_decrease': 0.0,\n",
       " 'stackingclassifier__gbdt_clf__min_impurity_split': None,\n",
       " 'stackingclassifier__gbdt_clf__min_samples_leaf': 1,\n",
       " 'stackingclassifier__gbdt_clf__min_samples_split': 2,\n",
       " 'stackingclassifier__gbdt_clf__min_weight_fraction_leaf': 0.0,\n",
       " 'stackingclassifier__gbdt_clf__n_estimators': 100,\n",
       " 'stackingclassifier__gbdt_clf__n_iter_no_change': None,\n",
       " 'stackingclassifier__gbdt_clf__presort': 'deprecated',\n",
       " 'stackingclassifier__gbdt_clf__random_state': None,\n",
       " 'stackingclassifier__gbdt_clf__subsample': 1.0,\n",
       " 'stackingclassifier__gbdt_clf__tol': 0.0001,\n",
       " 'stackingclassifier__gbdt_clf__validation_fraction': 0.1,\n",
       " 'stackingclassifier__gbdt_clf__verbose': 0,\n",
       " 'stackingclassifier__gbdt_clf__warm_start': False}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8022388059701493"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model = RandomForestClassifier(random_state=42)\n",
    "# model = LogisticRegression(random_state=42)\n",
    "# model = GradientBoostingClassifier(random_state=42)\n",
    "# model = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('mlp_clf', MLPClassifier()),\n",
    "# #         ('log_clf', LogisticRegression()),\n",
    "#         ('ab_clf', AdaBoostClassifier()),\n",
    "# #         ('svm_clf', SVC(probability=True)),\n",
    "#         ('rf_clf', RandomForestClassifier(n_estimators=100)),\n",
    "#         ('gbdt_clf', GradientBoostingClassifier())\n",
    "#     ], voting='soft')\n",
    "\n",
    "# gg.get_params('votingclassifier')\n",
    "# for m in model.estimators_:\n",
    "#     m\n",
    "#     X_test = data_pipeline.transform(X_test)\n",
    "#     m.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:02:17.217524Z",
     "iopub.status.busy": "2020-03-01T09:02:17.214661Z",
     "iopub.status.idle": "2020-03-01T09:02:17.294481Z",
     "shell.execute_reply": "2020-03-01T09:02:17.285203Z",
     "shell.execute_reply.started": "2020-03-01T09:02:17.216792Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# models = [\n",
    "#     MLPClassifier(),\n",
    "#     AdaBoostClassifier(),\n",
    "#     SVC(probability=True),\n",
    "#     LogisticRegression(C=0.1,max_iter=100),\n",
    "#     RandomForestClassifier(n_estimators=100,max_depth=6,oob_score=True),\n",
    "#     GradientBoostingClassifier(learning_rate=0.3,max_depth=6,n_estimators=100)\n",
    "# ]\n",
    "\n",
    "\n",
    "models=[\n",
    "    ('mlp_clf', MLPClassifier()),\n",
    "    ('ab_clf', AdaBoostClassifier()),\n",
    "    ('log_clf', LogisticRegression()),\n",
    "    ('svm_clf', SVC(probability=True)),\n",
    "    ('rf_clf', RandomForestClassifier()),\n",
    "    ('gbdt_clf', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "model = StackingClassifier(estimators=models, final_estimator=RandomForestClassifier())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:06:49.709619Z",
     "iopub.status.busy": "2020-03-01T09:06:49.707072Z",
     "iopub.status.idle": "2020-03-01T09:06:50.440559Z",
     "shell.execute_reply": "2020-03-01T09:06:50.438982Z",
     "shell.execute_reply.started": "2020-03-01T09:06:49.709086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('functiontransformer-1',\n",
       "                                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function set_child_type at 0x1a1ec37440>,\n",
       "                                                                                       inv_kw_args=None,...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7873134328358209"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7873\n"
     ]
    }
   ],
   "source": [
    "gg = full_pipeline(model)\n",
    "gg.fit(X_train, Y_train) \n",
    "\n",
    "gg.score(X_test, Y_test)\n",
    "Y_pred = gg.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T08:58:43.424389Z",
     "start_time": "2020-02-26T08:58:43.252887Z"
    },
    "execution": {
     "iopub.execute_input": "2020-03-01T08:08:10.422388Z",
     "iopub.status.busy": "2020-03-01T08:08:10.421909Z",
     "iopub.status.idle": "2020-03-01T08:08:10.687069Z",
     "shell.execute_reply": "2020-03-01T08:08:10.681398Z",
     "shell.execute_reply.started": "2020-03-01T08:08:10.422302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maowei/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:430: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "predictions = gg.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 记录结果\n",
    "1. stacking：0.79425\n",
    "2. voting：0.78947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T09:07:38.604823Z",
     "iopub.status.busy": "2020-03-01T09:07:38.602535Z",
     "iopub.status.idle": "2020-03-01T09:07:38.747437Z",
     "shell.execute_reply": "2020-03-01T09:07:38.745631Z",
     "shell.execute_reply.started": "2020-03-01T09:07:38.604394Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-a451a9aeb5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef'"
     ]
    }
   ],
   "source": [
    "model.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-03-01T08:42:35.678305Z",
     "iopub.status.busy": "2020-03-01T08:42:35.676093Z",
     "iopub.status.idle": "2020-03-01T08:42:35.796796Z",
     "shell.execute_reply": "2020-03-01T08:42:35.795160Z",
     "shell.execute_reply.started": "2020-03-01T08:42:35.678200Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer pipeline-1 (type Pipeline) does not provide get_feature_names.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-6d408b7e85d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 raise AttributeError(\"Transformer %s (type %s) does not \"\n\u001b[1;32m    362\u001b[0m                                      \u001b[0;34m\"provide get_feature_names.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                                      % (str(name), type(trans).__name__))\n\u001b[0m\u001b[1;32m    364\u001b[0m             feature_names.extend([name + \"__\" + f for f in\n\u001b[1;32m    365\u001b[0m                                   trans.get_feature_names()])\n",
      "\u001b[0;31mAttributeError\u001b[0m: Transformer pipeline-1 (type Pipeline) does not provide get_feature_names."
     ]
    }
   ],
   "source": [
    "data_pipeline.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "record_timing": true,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
